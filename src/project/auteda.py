# -*- coding: utf-8 -*-
"""autEDA.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IMCBPdZ5iofpXmK9jV-_pj8BwJiEjy3D
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, StandardScaler, OrdinalEncoder, OneHotEncoder
from sklearn.impute import KNNImputer
from scipy import stats
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

class AutomatedEDA:
    """
    Fully automated exploratory data analysis and preprocessing class.

    This class detects column types, handles missing values, scales numeric data,
    detects outliers, performs normality checks, encodes categorical/binary variables,
    and provides optional imbalance reporting and resampling (SMOTE/undersampling).

    Attributes:
    -----------
    df : pd.DataFrame
        Original dataframe
    numeric_cols : list
        Detected numeric columns
    categorical_cols : list
        Detected categorical columns
    binary_cols : list
        Detected binary columns (0/1 or bool)
    """

    def __init__(self, df):
        """
        Initialize with a dataframe and automatically detect column types.
        """
        self.df = df.copy()
        self.detect_column_types()

    def _detect_column_types(self):
    """
    Identify numeric, binary, and categorical columns automatically.

    Rules:
    - Binary columns include:
        * Boolean dtype
        * Numeric with only {0,1}
        * Object/category with exactly 2 unique values
    - Numeric columns: all numeric columns not identified as binary
    - Categorical columns: object/category with > 2 unique values
    """
    # Start with numeric and categorical detection
    numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
    object_cols = self.df.select_dtypes(include=['object', 'category']).columns.tolist()

    self.binary_cols = []
    self.numeric_cols = []
    self.categorical_cols = []

    # Check numeric columns for binary
    for col in numeric_cols:
        unique_vals = set(self.df[col].dropna().unique())
        if unique_vals.issubset({0, 1}):
            self.binary_cols.append(col)
        else:
            self.numeric_cols.append(col)

    # Check object/category columns
    for col in object_cols:
        unique_vals = self.df[col].dropna().unique()
        if len(unique_vals) == 2:  # treat as binary
            self.binary_cols.append(col)
        else:
            self.categorical_cols.append(col)

    # Add boolean dtype directly
    self.binary_cols += self.df.select_dtypes(include=['bool']).columns.tolist()

    # ------------------- Missing Value Handling -------------------
    def fill_missing(self, method_numeric='median', method_binary='mode', method_categorical='none', knn_cols=None, knn_neighbors=3):
        """
        Fill missing values in the dataset.
        - Numeric: median or mean
        - Binary: mode or KNN
        - Categorical: 'none' or mode
        - KNN: optionally impute multiple columns using KNN imputer
        """
        # Numeric
        for col in self.numeric_cols:
            if method_numeric == 'median':
                self.df[col] = self.df[col].fillna(self.df[col].median())
            elif method_numeric == 'mean':
                self.df[col] = self.df[col].fillna(self.df[col].mean())

        # Binary
        for col in self.binary_cols:
            if method_binary == 'mode':
                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])

        # Categorical
        for col in self.categorical_cols:
            if method_categorical == 'none':
                self.df[col] = self.df[col].fillna('none')
            elif method_categorical == 'mode':
                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])

        # KNN imputation
        if knn_cols:
            knn = KNNImputer(n_neighbors=knn_neighbors)
            self.df[knn_cols] = knn.fit_transform(self.df[knn_cols])

    # ------------------- Scaling -------------------
    def scale_numeric(self, method='minmax'):
        """Scale numeric columns using MinMax or Standard scaling."""
        if method == 'minmax':
            scaler = MinMaxScaler()
        elif method == 'standard':
            scaler = StandardScaler()
        else:
            raise ValueError("Scaling method must be 'minmax' or 'standard'")

        self.df[self.numeric_cols] = scaler.fit_transform(self.df[self.numeric_cols])

    # ------------------- Log Transform -------------------
    def log_transform(self, cols=None):
        """Apply log10 transform to specified numeric columns."""
        if cols is None:
            cols = self.numeric_cols
        for col in cols:
            self.df[col] = np.log10(self.df[col].replace(0, np.nan)).fillna(0)

    # ------------------- Outlier Detection -------------------
    def detect_outliers(self, method='zscore', threshold=3.0, plot=True):
        """
        Detect and optionally remove outliers.
        - method: 'zscore', 'iqr', 'qq'
        """
        outlier_report = []
        for col in self.numeric_cols:
            data = self.df[col]
            if method == 'zscore':
                mask = np.abs(stats.zscore(data, nan_policy='omit')) > threshold
            elif method == 'iqr':
                Q1, Q3 = np.percentile(data, [25, 75])
                IQR = Q3 - Q1
                mask = (data < Q1 - threshold*IQR) | (data > Q3 + threshold*IQR)
            elif method == 'qq':
                (osm, osr), _ = stats.probplot(data, dist="norm")
                mask = np.abs(osr - osm) > np.quantile(np.abs(osr - osm), 1 - (1/threshold))
            else:
                raise ValueError("Method must be 'zscore', 'iqr', or 'qq'")

            n_outliers = mask.sum()
            pct = n_outliers / len(data) * 100
            outlier_report.append([col, n_outliers, len(data), pct])

            # Drop outliers
            self.df = self.df.loc[~mask]

            if plot:
                fig, axs = plt.subplots(1, 2, figsize=(10, 4))
                sns.histplot(data, bins=30, ax=axs[0], kde=True)
                axs[0].set_title(f"{col} - Before (n={len(data)})")
                sns.histplot(self.df[col], bins=30, ax=axs[1], kde=True)
                axs[1].set_title(f"{col} - After (n={len(self.df[col])})")
                plt.show()

        return pd.DataFrame(outlier_report, columns=['Variable','Outliers Removed','Total','Percent Removed'])

    # ------------------- Normality Checks -------------------
    def check_normality(self):
        """Check normality of numeric columns: Shapiro-Wilk, D’Agostino K², skewness, kurtosis."""
        normality_results = []
        for col in self.numeric_cols:
            data = self.df[col].dropna()
            stat_sw, p_sw = stats.shapiro(data)
            stat_k2, p_k2 = stats.normaltest(data)
            skew = stats.skew(data)
            kurt = stats.kurtosis(data)
            normality_results.append([col, stat_sw, p_sw, stat_k2, p_k2, skew, kurt])
        return pd.DataFrame(normality_results,
                            columns=['Variable','Shapiro_Stat','Shapiro_p','Dagostino_Stat','Dagostino_p','Skewness','Kurtosis'])

    # ------------------- Encoding -------------------
    def encode_categorical(self, ordinal_mappings=None):
        """
        Encode categorical columns.
        - ordinal_mappings: dict like {'state': ['Early','Healthy','Advanced']}
        - Binary columns with string values are converted to 0/1
        - Remaining categorical columns are one-hot encoded
        """
        # Ordinal encoding
        if ordinal_mappings:
            for col, order in ordinal_mappings.items():
                enc = OrdinalEncoder(categories=[order])
                self.df[col] = enc.fit_transform(self.df[[col]])

        # Binary string to 0/1
        for col in self.binary_cols:
            if self.df[col].dtype == 'object':
                self.df[col] = self.df[col].map({self.df[col].unique()[0]:0,
                                                 self.df[col].unique()[1]:1})

        # One-hot encoding for remaining categoricals
        remaining = [col for col in self.categorical_cols if col not in (ordinal_mappings or {})]
        if remaining:
            self.df = pd.get_dummies(self.df, columns=remaining, drop_first=True)

    # ------------------- Imbalance Reporting -------------------
    def report_imbalance(self, target_cols=None, plot=True):
        """
        Report imbalance for binary/categorical columns.
        - target_cols: list of columns to check. If None, checks all binary + categorical columns
        """
        if target_cols is None:
            target_cols = self.binary_cols + self.categorical_cols
        imbalance_report = {}
        for col in target_cols:
            counts = self.df[col].value_counts()
            percentages = self.df[col].value_counts(normalize=True)*100
            imbalance_report[col] = pd.concat([counts, percentages], axis=1, keys=['Count','Percent'])

            if plot:
                sns.countplot(x=col, data=self.df)
                plt.title(f'Distribution of {col}')
                plt.show()
        return imbalance_report

    # ------------------- Optional SMOTE / Undersampling -------------------
    def resample(self, target_col, method='smote', sampling_strategy='not majority', random_state=42):
        """
        Resample dataset to handle imbalance.
        - method: 'smote' or 'undersample'
        - sampling_strategy: see imblearn documentation
        """
        X = self.df.drop(columns=target_col)
        y = self.df[target_col]

        if method == 'smote':
            sampler = SMOTE(sampling_strategy=sampling_strategy, random_state=random_state)
        elif method == 'undersample':
            sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=random_state)
        else:
            raise ValueError("method must be 'smote' or 'undersample'")

        X_res, y_res = sampler.fit_resample(X, y)
        self.df = pd.concat([X_res, y_res], axis=1)
        return self.df